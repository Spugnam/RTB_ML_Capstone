{"cells":[{"cell_type":"code","source":["%run Users/quentin.picard@gmail.com/Shared_Team/Helpers"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["# Load Data"],"metadata":{}},{"cell_type":"code","source":["impressions = spark.read.parquet('/mnt/nycdsa/yongguang/impressions_mini_final/')"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.functions import *\n# impressions.groupBy('landingPage').count().count()\nimpressions.agg(approx_count_distinct(impressions.zip)).collect()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["# Feature Engineering"],"metadata":{}},{"cell_type":"code","source":["allColumns = ['campaign', 'adSize', 'adType', 'deviceType', 'gender', 'os', 'landingPage', \\\n              'region', 'country', 'venueType', 'timestamp', 'iabCategories', 'age', 'clicked', 'TrainTestFlag']\nimpressions = impressions.select(*allColumns)\ncatTransformer = iabCategoriesTransformer(inputCol=\"iabCategories\")\nimpressions = catTransformer.transform(impressions)\nimpressions = cleanup_age_category(impressions)\nimpressions = cleanup_gender(impressions)\nimpressions = cleanup_os(impressions)\nimpressions = clean_landingPage(impressions)\nimpressions = cleanup_country(impressions)\nimpressions = format_region(impressions)\nimpressions = reduce_cardinality(impressions, 'region', 55)\nimpressions = cleanup_timestamp(impressions)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(impressions)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["# Modeling"],"metadata":{}},{"cell_type":"code","source":["train, test = impressions.filter(impressions.TrainTestFlag==0), impressions.filter(impressions.TrainTestFlag==1)\n\ntrain.cache()\ntest.cache()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["train_tiny = train.sampleBy('clicked', fractions={0: 0.01, 1: 0.01}, seed=0)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Class Weighting Begin (Optional)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nbalanceRatio = lambda df: (1 - float(df.where(df.clicked == 0).count())/df.count())\ncalculateWeights = udf(lambda d, br: 1 * br if d==0.0 else (1 * (1.0 - br)), DoubleType())"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["train =\\\ntrain.withColumn('classWeight', calculateWeights(train.clicked, lit(balanceRatio(train))))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### / Class Weighting End"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, OneHotEncoder \n\ncategoricalColumns = [ \"region\", \"adSize\", \"adType\", \"deviceType\", \"gender\", \"landingPage\",\\\n                      \"os\", \"venueType\", \"ageGroup\", \"timestamp_weekday\", \"timestamp_hour\"] #\"landingPage\", \n\nindexStages = []\nfor categoricalCol in categoricalColumns:\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\", handleInvalid=\"skip\")\n  indexStages.append(stringIndexer)\n\nencodeStages = []\nfor categoricalCol in categoricalColumns:\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"ClassVec\")\n  encodeStages.append(encoder)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nnumericalColumns = [\"IAB\"+str(i) for i in range(1, 27)]\n\nAssembler = VectorAssembler(inputCols= numericalColumns + \\\n                                      [categoricalCol + \"ClassVec\" for categoricalCol in categoricalColumns], \n                            outputCol=\"features\")"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\n\nlr = LogisticRegression(featuresCol=\"features\", \n                        labelCol=\"clicked\")\n#                         weightCol=\"classWeight\") # apply weights to observations\n\nlrPipeline = Pipeline(stages = indexStages + encodeStages +[Assembler, lr])\n\nlrModel = lrPipeline.fit(train_tiny)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["lrPredict = lrModel.transform(test)\nlrPredict.crosstab('prediction', 'clicked').show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["def lr_model_summary(model, test_data):\n  '''\n  \n  '''\n  model_fe = model.copy()\n  model_fe.stages = model_fe.stages[:-1]\n  return model.stages[-1].summary, model.stages[-1].evaluate(model_fe.transform(test_data))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["train_summary, test_summary = lr_model_summary(lrModel,test)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["import matplotlib.pyplot as plt\ntrain_summary.objectiveHistory"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["lr.explainParam(regParam)\n# lr.getMaxIter()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["train_summary.totalIterations"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["lrModelSummary = model_summary(lrModel, test)\nlrModelSummary.areaUnderROC"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Area under precision-recall curve\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator_PR = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",\n                                         labelCol=\"clicked\",\n                                         metricName=\"areaUnderPR\")\nlr_AUPR = evaluator_PR.evaluate(lrPredict)\nprint lr_AUPR"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#plot_evaluation_curve([lrModel, lr_constant_class_weight_downsample], ['lr_balance_class_weight_downsample', 'lr_constant_class_weight_downsample'], test, curve_type='pr')"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["from sklearn.metrics import log_loss\n\nlog_loss(y_true, y_score, eps=1e-15, normalize=True) # Quentin: to add"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["plot_evaluation_curve([lrModel], ['lrModel'], test)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["lr_constant_class_weight_downsample = lrModel.copy()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["# Save Model"],"metadata":{}},{"cell_type":"code","source":["lrModel.write().overwrite().save('/mnt/nycdsa/yongguang/models/lr_constant_class_weight')"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["lr_balanced_class_weight = lrModel.copy()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["Daniel: looking at coefficients"],"metadata":{}},{"cell_type":"code","source":["lrPredict.printSchema()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["display(lrPredict.select(categoricalColumns + [x + 'ClassVec' for x in categoricalColumns]))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["display(lrPredict.select('rawPrediction', 'features', 'probability','prediction'))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["log_reg_model = lrModel.stages[-1]"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["type(str(log_reg_model.summary.featuresCol))"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["from itertools import chain\n\nattrs = sorted(\n    (attr[\"idx\"], attr[\"name\"]) for attr in (chain(*lrPredict\n        .schema[str(log_reg_model.summary.featuresCol)]\n        .metadata[\"ml_attr\"][\"attrs\"].values())))"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["features_coef = [(name, log_reg_model.coefficients[idx]) for idx, name in attrs]"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["features_coef"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["import matplotlib.pyplot as plt; plt.rcdefaults()\nimport numpy as np\nimport matplotlib.pyplot as plt\n \nobjects = [x[0] for x in features_coef]\ny_pos = np.arange(len(features_coef))\ncoefficients = [x[1] for x in features_coef]\n\nplt.clf()\nplt.figure(figsize = (15,35))\nplt.barh(y_pos, coefficients, align='center', alpha=0.5)\nplt.yticks(y_pos, objects)\nplt.xlabel('Normalized Feature Weights')\nplt.title('LR Model Coefficients')\n \ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["trainingSummary = log_reg_model.summary"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["trainingSummary."],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["# Print the coefficients and intercept for linear regression\nprint(\"Coefficients: %s\" % str(log_reg_model.coefficients))\nprint(\"Intercept: %s\" % str(log_reg_model.intercept))\n\n# Summarize the model over the training set and print out some metrics\ntrainingSummary = log_reg_model.summary\nprint(\"numIterations: %d\" % trainingSummary.totalIterations)\nprint(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["print(\"areaUnderROC: %f\" % trainingSummary.areaUnderROC)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator_ROC = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",\n                                         labelCol=\"clicked\",\n                                         metricName=\"areaUnderROC\")\nlr_AUROC = evaluator_ROC.evaluate(lrPredict)\nprint lr_AUROC"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["# Obtain the objective per iteration\nobjectiveHistory = trainingSummary.objectiveHistory\nprint(\"objectiveHistory:\")\nfor objective in objectiveHistory:\n    print(objective)\n\n# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\ntrainingSummary.roc.show()\nprint(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n\n# Set the model threshold to maximize F-Measure\nfMeasure = trainingSummary.fMeasureByThreshold\nmaxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\nbestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n    .select('threshold').head()['threshold']\nlr.setThreshold(bestThreshold)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["display(lrModelSummary.pr) # this ignores class weights, which might give invalid results"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["# Model Selection via Cross-Validation"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["dbutils.fs.ls('/mnt/nycdsa/yongguang/models/')"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["from pyspark.ml import PipelineModel\n\ntemp = PipelineModel.load('dbfs:/mnt/nycdsa/yongguang/lr_constant_class_weight/')"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["# hi dimitri :)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":62}],"metadata":{"name":"1. Simple Logistic Regression","notebookId":2532572650593654},"nbformat":4,"nbformat_minor":0}
