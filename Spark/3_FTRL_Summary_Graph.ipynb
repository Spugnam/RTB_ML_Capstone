{"cells":[{"cell_type":"code","source":["%run ../Helpers"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["impressions = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/impressions_final2/') # 4,714,433 count, training where day < 12\n# impressions = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/impressions_20ads/')"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["impressions = cleanup_gender(impressions)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["age_as_category=1\nif(age_as_category):\n  impressions = cleanup_age_category(impressions)\nelse:\n  impressions = cleanup_age_numeric(impressions) "],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["impressions = cleanup_timestamp(impressions)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["impressions = format_region(impressions)\nimpressions = reduce_cardinality(impressions, \"region\", 55, mode=0)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["impressions = iab_encoder(impressions, \"iabCategories\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["impressions = clean_landingPage(impressions)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["impressions = clean_bestVenueName(impressions)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# from pyspark.sql.functions import col\n\n# impressions = interaction(impressions, col(\"campaign\"), col(\"bestVenueName\"), \"campaign-bestVenueName\")\n# impressions = interaction(impressions, col(\"landingPage\"), col(\"bestVenueName\"), \"landingPage-bestVenueName\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["print(\"Categorical variables in impressions dataframe: \")\nprint([item[0] for item in impressions.dtypes if item[1].find('string') > -1])\nprint(\"\\r\")\ncategoricalColumns = ['adSize', 'adType', 'ageGroup', 'bestVenueName', 'carrier', 'deviceName', 'deviceType', 'exchange', 'gender', 'landingPage', 'os', 'region', 'timestamp_hour', 'timestamp_weekday', 'targetGroup', 'zip'] \n\n# targetGroup numeric treated as categorical\nprint(\"Categorical variables used in model: \")\nprint(categoricalColumns)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["all_numerical_columns = [item[0] for item in impressions.dtypes if (item[1].find('int') > -1) | (item[1].find('double') > -1)] \nprint(\"Numerical variables in impressions dataframe: \")\nprint(all_numerical_columns)\nprint(\"\\r\")\nexcluded_numerical = ['backendStatus', 'bidPrice', 'elbStatus', 'location', 'month', 'price', '', 'year', 'TrainTestFlag']\nprint(\"Excluded numerical variables: \")\nprint(excluded_numerical)\nprint(\"\\r\")\nnumericalColumns = [x for x in all_numerical_columns if x not in excluded_numerical]\nprint(\"Numerical variables used in model (including computed): \")\nprint(numericalColumns)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["impressions = impressions.select(*(categoricalColumns + numericalColumns))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["display(impressions)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["impressions.printSchema()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# impressions.write.mode('overwrite').parquet('dbfs:/mnt/nycdsa/quentin/impressions_pre_processed/')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["display(dbutils.fs.ls('dbfs:/mnt/nycdsa/quentin/'))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["impressions = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/impressions_pre_processed/') # 4714433 count, training where day < 12"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["train, test = impressions.filter(impressions.day<12),\\\n              impressions.filter(impressions.day >= 12) # predict next days\ntrain.cache()\ntest.cache()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["train.groupby('clicked').count().show()\n# print(test.count())"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# train.groupBy(\"day\").agg({\"*\": \"count\"}).show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["from datetime import datetime\nfrom math import exp, log, sqrt\nimport mmh3\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf8') # prevents ASCII crash\n# import pyspark class Row from module sql\nfrom pyspark.sql import Row\n\n\n##############################################################################\n# class, function, generator definitions #####################################\n##############################################################################\n\nclass ftrl_proximal(object):\n    ''' Follow the regularized leader - proximal\n        this is an adaptive-learning-rate sparse logistic-regression with\n        efficient L1-L2-regularization\n    '''\n\n    def __init__(self, alpha, beta, L1, L2, D, interaction, epoch):\n        # parameters\n        self.alpha = alpha\n        self.beta = beta\n        self.L1 = L1\n        self.L2 = L2\n        self.epoch = epoch\n\n        # feature related parameters\n        self.D = D\n        self.interaction = interaction\n\n        # model\n        # n: squared sum of past gradients\n        # z: weights\n        # w: lazy weights\n        self.n = [0.] * D\n        self.z = [0.] * D\n        self.w = {}\n\n    def _indices(self, x):\n        ''' A helper generator that yields the indices in x\n\n            The purpose of this generator is to make the following\n            code a bit cleaner when doing feature interaction.\n        '''\n\n        # first yield index of the bias term\n        yield 0\n\n        # then yield the normal indices\n        for index in x:\n            yield index\n\n        # now yield interactions (if applicable)\n        if self.interaction:\n            D = self.D\n            L = len(x)\n\n            x = sorted(x)\n            for i in xrange(L):\n                for j in xrange(i+1, L):\n                    # one-hot encode interactions with hash trick\n                    yield mmh3.hash(str(x[i]) + '_' + str(x[j]), signed=False) % D\n\n    def get_prob(self, x):\n        ''' Get probability estimation on x\n\n            INPUT:\n                x: features\n\n            OUTPUT:\n                probability of p(y = 1 | x; w)\n        '''\n\n        # parameters\n        alpha = self.alpha\n        beta = self.beta\n        L1 = self.L1\n        L2 = self.L2\n\n        # model\n        n = self.n\n        z = self.z\n        w = {}\n\n        # wTx is the inner product of w and x\n        wTx = 0.\n        for i in self._indices(x):\n            sign = -1. if z[i] < 0 else 1.  # get sign of z[i]\n\n            # build w on the fly using z and n, hence the name - lazy weights\n            # we are doing this at prediction instead of update time is because\n            # this allows us for not storing the complete w\n            if sign * z[i] <= L1:\n                # w[i] vanishes due to L1 regularization\n                w[i] = 0.\n            else:\n                # apply prediction time L1, L2 regularization to z and get w\n                w[i] = (sign * L1 - z[i]) / ((beta + sqrt(n[i])) / alpha + L2)\n\n            wTx += w[i]\n\n        # cache the current w for update stage\n        self.w = w\n\n        # bounded sigmoid function, this is the probability estimation\n        return 1. / (1. + exp(-max(min(wTx, 35.), -35.)))\n\n    def update(self, x, p, y):\n        ''' Update model using x, p, y\n\n            INPUT:\n                x: feature, a list of indices\n                p: click probability prediction of our model\n                y: answer\n\n            MODIFIES:\n                self.n: increase by squared gradient\n                self.z: weights\n        '''\n\n        # parameter\n        alpha = self.alpha\n\n        # model\n        n = self.n\n        z = self.z\n        w = self.w\n\n        # gradient under logloss\n        g = p - y\n\n        # update z and n\n        for i in self._indices(x):\n            sigma = (sqrt(n[i] + g * g) - sqrt(n[i])) / alpha\n            z[i] += g - sigma * w[i]\n            n[i] += g * g\n            \n            \n    def fit(self, df): \n      start = datetime.now()\n      \n      D = self.D\n      epoch = self.epoch\n\n      # start training\n      for e in xrange(epoch):\n          loss = 0.\n          count = 0\n\n          for t, x, y in data(df, D):  # data is a generator\n              #    t: just a instance counter\n              #    x: features\n              #    y: label (click)\n\n              # step 1, get prediction from learner\n              p = learner.get_prob(x)\n\n              if (holdout and t % holdout == 0):\n                  # step 2-1, calculate validation loss\n                  #           we do not train with the validation data so that our\n                  #           validation loss is an accurate estimation\n                  #\n                  # holdout: validate with every N instance, train with others\n                  loss += logloss(p, y)\n                  count += 1\n              else:\n                  # step 2-2, update learner with label (click) information\n                  self.update(x, p, y)\n\n          if (holdout):\n            print('Epoch %d finished, validation logloss: %f, elapsed time: %s' % (\n              e, loss/count, str(datetime.now() - start)))\n          \n    def predict(self, df):  # add as method 'predict' of ftrl_proximal class\n      \n      D = self.D\n      \n      prob_list = list()\n      for t, x, y in data(df, D):\n        p = self.get_prob(x)\n        prob_list.append(p)\n    #     print(t, p)\n      return prob_list\n    \n    def save(self, filename, folder_path=\"/mnt/nycdsa/quentin/models/\"):\n      import os\n      \n      n = self.n\n      z = self.z\n\n      model = sqlContext.createDataFrame([Row(n= n[i], z=z[i]) for i in range(len(n))])\n      model_path = os.path.join(folder_path, filename)\n      model.coalesce(1).write.csv(model_path, mode='overwrite')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["def logloss(p, y):\n    ''' FUNCTION: Bounded logloss\n\n        INPUT:\n            p: our prediction\n            y: real answer\n\n        OUTPUT:\n            logarithmic loss of p given y\n    '''\n\n    p = max(min(p, 1. - 10e-15), 10e-15)\n    return -log(p) if y == 1. else -log(1. - p)\n\n\ndef data(df, D):\n    ''' GENERATOR: Apply hash-trick to input dataframe\n                   and for simplicity, we one-hot-encode everything\n\n        INPUT:\n            path: path to training or testing file\n            D: the max index that we can hash to\n\n        YIELDS:\n            x: a list of hashed and one-hot-encoded 'indices'\n               we only need the index since all values are either 0 or 1\n            y: y = 1 if we have a click, else we have y = 0\n    '''\n      \n    for t, row in enumerate(df.rdd.toLocalIterator()):\n        # process clicks\n        y = 0.\n        if 'clicked' in row:\n            if row['clicked'] == 1:\n              y = 1.\n        \n        # build x\n        x = []\n        for key in df.columns:\n          if (key != 'clicked'): # do not use label!\n            value = str(row[key]).encode('utf-8')\n            # one-hot encode everything with hash trick\n            index = hash(key + '_' + value) % D\n            x.append(index)\n        yield t, x, y"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["holdout = None\nparams = {'alpha': .1, # learning rate\n              'beta': 1., # smoothing parameter for adaptive learning rate\n             'L1': 0.05, # L1 regularization, larger value means more regularized\n             'L2': 0.05, # L2 regularization, larger value means more regularized\n             'D': 2 ** 20, # number of weights to use\n             'interaction': False, # whether to enable poly2 feature interactions\n             'epoch': 1} # learn training data for N passes\n\n# initialize learner\nlearner = ftrl_proximal(**params)\n\nlearner.fit(train)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# distinct features \nprint(len(learner.z) - learner.z.count(0))\nlearner.z[:10]"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["learner.save(\"model_zip_targetGroup\", \"/mnt/nycdsa/quentin/models/\")"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["##############################################################################\n# Prediction  ##########################\n##############################################################################\ntest = test[test['day'].isin([12, 13, 14, 15, 16, 17, 18, 19])]\nprobas = learner.predict(test.drop(\"clicked\"))\nprobas\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["import numpy as np\nprobas_array = np.asarray(probas)\nclicks_array = np.asarray(test.select('clicked').collect())"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["model_FTRL = sqlContext.createDataFrame([Row(np.asscalar(clicks_array[i]), np.asscalar(probas_array[i])) for i in range(len(clicks_array))], \n                                       [\"Labels\", \"Probability\"])\nmodel_FTRL.write.mode('overwrite').parquet('dbfs:/mnt/nycdsa/quentin/graph/model_FTRL_7_days_test')"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import log_loss\n\nprint(\"roc_auc_score\",\n      roc_auc_score(clicks_array, probas_array, average=\"macro\"))\n\nprint(\"average_precision_score\",\n      average_precision_score(clicks_array, probas_array, average=\"macro\"))\n\nprint(\"log_loss: \",\n      log_loss(clicks_array, probas_array, eps=1e-15, normalize=True))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# display(model_FTRL)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["display(dbutils.fs.ls('/mnt/nycdsa/quentin/graph/'))"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# Models to load\nsimple_logistic = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/simple_logistic/')\n\n# model_dt = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/model_dt/')\nmodel_dt3deep = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/model_dt3deep/').withColumnRenamed('clicked', 'Labels').withColumnRenamed('probability', 'Probability')\nmodel_rf = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/model_rf/').withColumnRenamed('clicked', 'Labels').withColumnRenamed('probability', 'Probability')\n\nmodel_FTRL = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/model_FTRL_7_days_test/')\nFTRL_full_data = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/model_FTRL_full_data/') "],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# display(simple_logistic)\n# display(model_dt)\ndisplay(model_dt3deep)\n# display(model_rf)\n# display(FTRL_full_data)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\n\n# Models:\n# dbfs:/mnt/nycdsa/quentin/graph/model_FTRL\n# dbfs:/mnt/nycdsa/quentin/graph/simple_logistic\n\nmodels = [simple_logistic, model_dt3deep, model_rf, model_FTRL, FTRL_full_data]\n\nlabels, scores = [], []\nfpr, tpr, auroc = [], [], []\n\n# Read all models\nfor model in models:\n  labels = np.array(model.select('Labels').collect())\n  scores = np.array(model.select('Probability').collect())\n  \n  fpr_temp, tpr_temp, _ = roc_curve(labels, scores)\n#   precision_recall_curve\n  fpr.append(fpr_temp)\n  tpr.append(tpr_temp)\n  auroc.append(roc_auc_score(labels, scores, average=\"macro\"))  "],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\nmodel_names = ['Simple Logistic', '3-level Decision Tree', 'Random Forest', 'FTLR', 'FTRL_full_data']\nfig, ax = plt.subplots()\nlw = 2\nfor i in range(len(models)):\n  ax.plot(fpr[i], tpr[i], lw=lw) \nax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\n\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver operating characteristic curve')\nax.legend(['%s (area = %0.3f)' % (model_names[i], auroc[i]) for i in range(len(model_names))], loc=\"lower right\")\n# legend(loc=\"lower right\")\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nimport numpy as np\n\n# Models:\n# dbfs:/mnt/nycdsa/quentin/graph/model_FTRL\n# dbfs:/mnt/nycdsa/quentin/graph/simple_logistic\n\nmodels = [simple_logistic, model_dt3deep, model_rf, model_FTRL, FTRL_full_data]\n\nlabels, scores = [], []\nprecision, recall, pr = [], [], []\n\n# Read all models\nfor model in models:\n  labels = np.array(model.select('Labels').collect())\n  scores = np.array(model.select('Probability').collect())\n  \n  precision_temp, recall_temp, _ = precision_recall_curve(labels, scores) # don't need to save thresholds\n#   precision_recall_curve\n  precision.append(precision_temp)\n  recall.append(recall_temp)\n  pr.append(average_precision_score(labels, scores))  "],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# min(precision[0][1:]-precision[0][:-1])\nsimple_logistic.agg({'Probability':'min'}).show()"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\nmodel_names = ['Simple Logistic', '3-level Decision Tree', 'Random Forest', 'FTLR', 'FTRL_full_data']\nfig, ax = plt.subplots()\nlw = 2\nfor i in range(len(models)):\n  ax.plot(precision[i], recall[i], lw=lw) \nax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1])\n\nax.set_xlabel('Recall')\nax.set_ylabel('Precision')\nax.set_title('Precision-Recall curve')\nax.legend(['%s (area = %0.3f)' % (model_names[i], pr[i]) for i in range(len(model_names))], loc=\"upper right\")\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# Full data AUPR\nfrom sklearn.metrics import average_precision_score\nprint(\"average_precision_score\",\n      average_precision_score(np.array(FTRL_full_data_df.select('Labels').collect()),\\\n                              np.array(FTRL_full_data_df.select('Probability').collect()), average=\"macro\"))"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["from sklearn.metrics import log_loss\n\n\nmodels = [simple_logistic, model_dt3deep, model_rf, model_FTRL, FTRL_full_data]\n\nlabels, scores = [], []\nll = []\nll_temp = 0\n\n# Read all models\nfor model in models:\n  labels = np.array(model.select('Labels').collect())\n  scores = np.array(model.select('Probability').collect())\n  ll_temp = log_loss(labels, scores, eps=1e-15, normalize=True)\n  ll.append(ll_temp)\n  print(\"log_loss: \", ll_temp)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["np.mean(labels) # 0.46% average CTR"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["labels = np.array(simple_logistic.select('Labels').collect())\nscores = np.array([np.mean(labels)] * labels.shape[0])\n\nprint(\"AUROC\", roc_auc_score(labels, scores, average=\"macro\"))\nprint(\"AUPR\", average_precision_score(labels, scores))\nprint(\"LogLoss: \", log_loss(labels, scores, eps=1e-15, normalize=True))"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["FTRL_full_data = spark.read.parquet('dbfs:/mnt/nycdsa/quentin/graph/model_FTRL_full_data/')"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["thresholds = [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.5]\n\nfor t in thresholds:\n  print(\"threshold : \", t)\n  FTRL_full_data.withColumn(\"Prediction\", FTRL_full_data[\"Probability\"] >= t).crosstab(\"Prediction\", \"Labels\").show()"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["from sklearn.model_selection import ParameterGrid\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import average_precision_score\n\n# holdout for logloss calculation\nholdout= None # use every N training instance for holdout validation\n# labels\nclicks_array = np.asarray(test.select('clicked').collect())\n\nparam_grid = {'alpha': [.1, .05], # learning rate\n              'beta': [1., 0.5], # smoothing parameter for adaptive learning rate\n             'L1': [0., .5, 1.], # L1 regularization, larger value means more regularized\n             'L2': [0., .5, 1.], # L2 regularization, larger value means more regularized\n             'D': [2 ** 20], # number of weights to use\n             'interaction': [False], # whether to enable poly2 feature interactions\n             'epoch': [1]} # learn training data for N passes\n\n\ngrid = ParameterGrid(param_grid)\n\nfor params in grid:\n  # print parameters\n  print(params)\n  \n  # train\n  learner = ftrl_proximal(**params)\n  learner.fit(train)\n  print(\"Non-zero weights: \", len(learner.z) - learner.z.count(0))\n  \n  # save model\n  learner.save(\"model_created_on_\" + str(datetime.now()), \"/mnt/nycdsa/quentin/models/\")\n  \n  # predict\n  probas_array = np.asarray(learner.predict(test.drop(\"clicked\")))\n  print(\"roc_auc_score\",\n      roc_auc_score(clicks_array, probas_array, average=\"macro\"))\n  print(\"average_precision_score\",\n      average_precision_score(clicks_array, probas_array, average=\"macro\"))"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/nycdsa/quentin/models\"))"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["# parameters \nholdout= None \nparams = {'interaction': False, 'D': 1048576, 'beta': 0.5, 'epoch': 1, 'L2': 0.5, 'L1': 0.0, 'alpha': 0.1}\n\n# save results in lists\nroc_list = []\npr_list = []\n\n# train\nlearner = ftrl_proximal(**params)\nlearner.fit(train)\nprint(\"Model trained. Non-zero weights: \", len(learner.z) - learner.z.count(0))\n\n# save model\nlearner.save(\"model_created_on_\" + str(datetime.now()), \"/mnt/nycdsa/quentin/models/\")\n\n# predict for all days\ndays = range(12, 23)\n\nfor day in days:\n  roc_temp = 0.\n  pr_temp = 0.\n  print(\"Starting day\", day)\n  \n  # define test\n  test_temp = test[test.day == day]\n  test_temp.cache()\n  print(\"Day: \", day, \"Number of impressions: \", test_temp.count())\n   \n  # predict\n  probas_array = np.asarray(learner.predict(test_temp.drop(\"clicked\"))) # probabilities\n  clicks_array = np.asarray(test_temp.select('clicked').collect()) # labels\n  # roc\n  roc_temp = roc_auc_score(clicks_array, probas_array, average=\"macro\")\n  roc_list.append(roc_temp)\n  print(\"roc_auc_score\", roc_temp)\n  # pr\n  pr_temp = average_precision_score(clicks_array, probas_array, average=\"macro\")\n  pr_list.append(pr_temp)\n  print(\"average_precision_score\", pr_temp)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["type(roc_list[0])\ntype(np.asscalar(roc_list[0]))"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["from pyspark.sql import Row\n\ndisplay(sqlContext.createDataFrame([Row(col1= days[i], col2=np.asscalar(roc_list[i]), col3=np.asscalar(pr_list[i])) for i in range(len(days))]))"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["from pyspark.sql import Row\n\ndisplay(sqlContext.createDataFrame([Row(col1= days[i], col2=np.asscalar(roc_list[i])) for i in range(len(days))]))"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["display(dbutils.fs.ls('dbfs:/mnt/nycdsa/quentin/graph'))"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["# dbutils.fs.rm(\"/mnt/nycdsa/quentin/models/model_created_on_2017-12-08 16:30:50.350543\", recurse=True)"],"metadata":{},"outputs":[],"execution_count":53}],"metadata":{"name":"3_FTRL_Summary_Graph","notebookId":3606330233151601},"nbformat":4,"nbformat_minor":0}
